{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6Xw8T-0gMK-j"
      },
      "outputs": [],
      "source": [
        "# !apt-get install python-dev libopenblas-dev\n",
        "# !git clone --recursive https://github.com/ibayer/fastFM.git\n",
        "# import os\n",
        "# os.chdir(\"./fastFM/\")\n",
        "# !pip install -r ./requirements.txt\n",
        "# !make\n",
        "# !PYTHON=python3 make\n",
        "# !pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3aFQIl0UMnfe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "path = \"./\"\n",
        "os.chdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XguLVs7RJiya"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import numpy as np\n",
        "import random\n",
        "import scipy\n",
        "from collections import defaultdict\n",
        "from fastFM import als\n",
        "from scipy.spatial import distance\n",
        "import csv\n",
        "import dateutil.parser\n",
        "from datetime import timedelta\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iXA2QhcwPhY0"
      },
      "outputs": [],
      "source": [
        "def MSE(predictions, labels):\n",
        "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
        "    return sum(differences) / len(differences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qd2OIoQTMfUF"
      },
      "outputs": [],
      "source": [
        "with open(\"Sampled_by_review_count_train_state.pkl\",\"rb\") as fp:\n",
        "    train_dicts = pickle.load(fp)\n",
        "\n",
        "with open(\"Sampled_by_review_count_val_state.pkl\",\"rb\") as fp:\n",
        "    val_dicts = pickle.load(fp)\n",
        "\n",
        "with open(\"Sampled_by_review_count_test_state.pkl\",\"rb\") as fp:\n",
        "    test_dicts = pickle.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_dicts = train_dicts + val_dicts + test_dicts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tsetfUN4Y36",
        "outputId": "d6277046-76bf-4e05-8855-63061a3c36fa"
      },
      "outputs": [],
      "source": [
        "train_val_dicts = train_dicts + val_dicts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akBAIiM8PdgC"
      },
      "outputs": [],
      "source": [
        "with open(\"Price_filtered_places.pkl\",\"rb\") as fp:\n",
        "    filtered_places = pickle.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lQNsqSJTVVin"
      },
      "outputs": [],
      "source": [
        "#Places mapping from place id to its attributes\n",
        "places_meta_data = defaultdict(dict)\n",
        "for d in filtered_places:\n",
        "  places_meta_data[d['gPlusPlaceId']] = d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EliMuVXtNkaq",
        "outputId": "fdc470bb-14e1-4aef-947e-16718f54b3a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'rating': 4.0,\n",
              " 'reviewerName': 'william spindler',\n",
              " 'reviewText': 'Best War Wanton soup in Red Bluff',\n",
              " 'categories': ['Asian Restaurant', 'Chinese Restaurant'],\n",
              " 'gPlusPlaceId': '106591714648856494903',\n",
              " 'unixReviewTime': 1394669496,\n",
              " 'reviewTime': 'Mar 12, 2014',\n",
              " 'gPlusUserId': '100000032416892623125',\n",
              " 'gps': [40.179159, -122.236162],\n",
              " 'parsed_time': 0.9989914778876909,\n",
              " 'state': 'CA'}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dicts[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yp9n0ITXNSaF"
      },
      "outputs": [],
      "source": [
        "users = set([x['gPlusUserId'] for x in all_dicts])\n",
        "nUsers = len(users)\n",
        "places = set([x['gPlusPlaceId'] for x in all_dicts])\n",
        "nPlaces = len(places)\n",
        "\n",
        "prices = set([x['price'] for x in filtered_places])\n",
        "nPrices = len(prices)\n",
        "\n",
        "user_di = {user:i for i,user in enumerate(list(users))}\n",
        "place_di = {place:i for i,place in enumerate(list(places))}\n",
        "price_di = {price:i for i,price in enumerate(list(prices))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8V5gXvO0OswX"
      },
      "outputs": [],
      "source": [
        "X = scipy.sparse.lil_matrix((len(train_val_dicts), nUsers + nPlaces + nPrices))\n",
        "\n",
        "for i in range(len(train_val_dicts)):\n",
        "    if len(places_meta_data[train_val_dicts[i]['gPlusPlaceId']]) != 0 and train_val_dicts[i]['gPlusUserId'] in user_di:\n",
        "        user = user_di[train_val_dicts[i]['gPlusUserId']]\n",
        "        item = place_di[train_val_dicts[i]['gPlusPlaceId']]\n",
        "        price = price_di[places_meta_data[train_val_dicts[i]['gPlusPlaceId']]['price']]\n",
        "        X[i,user] = 1 # One-hot encoding of user\n",
        "        X[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "        X[i,nUsers + nPlaces+price] = 1\n",
        "\n",
        "y = np.array([d['rating'] for d in train_val_dicts])\n",
        "print(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 495,
      "metadata": {},
      "outputs": [],
      "source": [
        "def keep_non_empty_rows(X, y):\n",
        "    X = X.tocsr()\n",
        "    non_empty_mask = X.getnnz(axis=1) > 0\n",
        "    return X[non_empty_mask], y[non_empty_mask]\n",
        "\n",
        "X, y = keep_non_empty_rows(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 497,
      "metadata": {},
      "outputs": [],
      "source": [
        "split = int(0.8*X.shape[0])\n",
        "X_train,y_train = X[:split],y[:split]\n",
        "X_val,y_val = X[split:],y[split:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFs72y6DPj98"
      },
      "outputs": [],
      "source": [
        "X_test = scipy.sparse.lil_matrix((len(test_dicts), nUsers + nPlaces + nPrices))\n",
        "\n",
        "for i in range(len(test_dicts)):\n",
        "  user_id = test_dicts[i]['gPlusUserId']\n",
        "\n",
        "  place_id = test_dicts[i]['gPlusPlaceId']\n",
        "\n",
        "  if(user_id in user_di and place_id in place_di and len(places_meta_data[train_val_dicts[i]['gPlusPlaceId']]) != 0):\n",
        "\n",
        "    user = user_di[user_id]\n",
        "    item = place_di[place_id]\n",
        "\n",
        "    price = price_di[places_meta_data[train_val_dicts[i]['gPlusPlaceId']]['price']]\n",
        "\n",
        "    X_test[i,user] = 1 # One-hot encoding of user\n",
        "    X_test[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "    X_test[i,nUsers + nPlaces+price] = 1\n",
        "\n",
        "  elif(user_id in user_di):\n",
        "    user = user_di[user_id]\n",
        "    X_test[i,user] = 1 # One-hot encoding of user\n",
        "  elif(place_id in place_di and len(places_meta_data[train_val_dicts[i]['gPlusPlaceId']]) != 0):\n",
        "    item = place_di[place_id]\n",
        "    price = price_di[places_meta_data[train_val_dicts[i]['gPlusPlaceId']]['price']]\n",
        "    X_test[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "    X_test[i,nUsers + nPlaces+price] = 1\n",
        "\n",
        "y_test = np.array([d['rating'] for d in test_dicts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test, y_test = keep_non_empty_rows(X_test, y_test)\n",
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 500,
      "metadata": {
        "id": "mJ9f4HMsPR1H"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-20 {color: black;background-color: white;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>FMRegression(l2_reg_V=50, l2_reg_w=20, n_iter=500, rank=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FMRegression</label><div class=\"sk-toggleable__content\"><pre>FMRegression(l2_reg_V=50, l2_reg_w=20, n_iter=500, rank=3)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "FMRegression(l2_reg_V=50, l2_reg_w=20, n_iter=500, rank=3)"
            ]
          },
          "execution_count": 500,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fm = als.FMRegression(n_iter=500, init_stdev=0.1, rank=3, l2_reg_w=20, l2_reg_V=50)\n",
        "fm.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHBFj9uMRxVl",
        "outputId": "05939a12-71f1-498e-b91b-761e48d6ee56"
      },
      "outputs": [],
      "source": [
        "y_pred_train = fm.predict(X_train)\n",
        "print(MSE(y_pred_train, y_train))\n",
        "\n",
        "y_pred_val = fm.predict(X_val)\n",
        "print(MSE(y_pred_val, y_val))\n",
        "\n",
        "y_test_pred = fm.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "U4_JHPwX_iXS"
      },
      "outputs": [],
      "source": [
        "time_li = [d['unixReviewTime'] for d in all_dicts if d['unixReviewTime']]\n",
        "max_time = max(time_li)\n",
        "\n",
        "users = set([x['gPlusUserId'] for x in all_dicts])\n",
        "nUsers = len(users)\n",
        "places = set([x['gPlusPlaceId'] for x in all_dicts])\n",
        "nPlaces = len(places)\n",
        "\n",
        "prices = set([x['price'] for x in filtered_places])\n",
        "nPrices = len(prices)\n",
        "\n",
        "user_di = {user:i for i,user in enumerate(list(users))}\n",
        "place_di = {place:i for i,place in enumerate(list(places))}\n",
        "price_di = {price:i for i,price in enumerate(list(prices))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Jzvcwyem3ijB"
      },
      "outputs": [],
      "source": [
        "mod_train_dicts = []\n",
        "allRatings = []\n",
        "ratingDict = {}\n",
        "userRatings = defaultdict(list) #all ratings given by user u\n",
        "placeRatings = defaultdict(list)\n",
        "usersPerPlace = defaultdict(set) # Maps an item to the users who rated it\n",
        "placesPerUser = defaultdict(set) # Maps a user to the items that they rated\n",
        "\n",
        "for d in all_dicts:\n",
        "  user = d['gPlusUserId']\n",
        "  place = d['gPlusPlaceId']\n",
        "  usersPerPlace[place].add(user)\n",
        "  placesPerUser[user].add(place)\n",
        "  r = int(d['rating'])\n",
        "  d['rating'] = r\n",
        "  ratingDict[(user,place)] = r\n",
        "  d['parsed_time'] = d['unixReviewTime']/max_time\n",
        "  # for key in recipe_meta_data[place]:\n",
        "  #   d[key] = recipe_meta_data[place][key]\n",
        "  allRatings.append(r)\n",
        "  userRatings[user].append((r,d['parsed_time']))\n",
        "  placeRatings[place].append((r,d['parsed_time']))\n",
        "  mod_train_dicts.append(d)\n",
        "\n",
        "globalAverage = sum(allRatings) / len(allRatings)\n",
        "userAverage = {}\n",
        "for u in userRatings:\n",
        "  userAverage[u] = sum([t[0] for t in userRatings[u]]) / len(userRatings[u])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx5KVwz6JE4O",
        "outputId": "6f18bab6-cc62-499a-f2a2-c04f5301cd1f"
      },
      "outputs": [],
      "source": [
        "review_count_per_user = [len(placesPerUser[user]) for user in placesPerUser]\n",
        "avg_review_count = sum(review_count_per_user)/len(review_count_per_user)\n",
        "avg_review_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "sorted_review_count = sorted(review_count_per_user,reverse=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Sampling scheme\n",
        "\n",
        "users_with_non1_rcount = [user for user in placesPerUser if len(placesPerUser[user]) >=2 ]\n",
        "users_with_1_rcount = [user for user in placesPerUser if len(placesPerUser[user]) ==1 ]\n",
        "users_with_1_rcount_subset = [random.choice(users_with_1_rcount) for _ in range(40000)]\n",
        "users_with_non1_rcount.extend(users_with_1_rcount_subset)\n",
        "user_list_sampled = set(users_with_non1_rcount)\n",
        "sampled_train_dict = [d for d in train_dicts if d['gPlusUserId'] in user_list_sampled]\n",
        "\n",
        "print(len(user_list_sampled))\n",
        "print(len(sampled_train_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 511,
      "metadata": {
        "id": "aJLO7oKiMqaY"
      },
      "outputs": [],
      "source": [
        "y_val_glob_avg = [globalAverage]*len(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3j99r1mM7PA",
        "outputId": "d440bdaf-959c-4e4e-844c-1dd86b8f28f1"
      },
      "outputs": [],
      "source": [
        "MSE(y_val,y_val_glob_avg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAMulR9wKebE"
      },
      "source": [
        "Vanilla FM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vBGXR1lKu8w"
      },
      "outputs": [],
      "source": [
        "X_train = scipy.sparse.lil_matrix((len(train_dicts), nUsers + nPlaces))\n",
        "\n",
        "for i in range(len(train_dicts)):\n",
        "    user = user_di[train_dicts[i]['gPlusUserId']]\n",
        "    item = place_di[train_dicts[i]['gPlusPlaceId']]\n",
        "    X_train[i,user] = 1 # One-hot encoding of user\n",
        "    X_train[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "\n",
        "y_train = np.array([d['rating'] for d in train_dicts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96ibVcocLnb1"
      },
      "outputs": [],
      "source": [
        "X_val = scipy.sparse.lil_matrix((len(val_dicts), nUsers + nPlaces))\n",
        "\n",
        "for i in range(len(val_dicts)):\n",
        "  user_id = val_dicts[i]['gPlusUserId']\n",
        "\n",
        "  place_id = val_dicts[i]['gPlusPlaceId']\n",
        "\n",
        "  if(user_id in user_di and  place_id in place_di):\n",
        "    user = user_di[user_id]\n",
        "    item = place_di[place_id]\n",
        "    X_val[i,user] = 1 # One-hot encoding of user\n",
        "    X_val[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "  elif(user_id in user_di):\n",
        "    user = user_di[user_id]\n",
        "    X_val[i,user] = 1 # One-hot encoding of user\n",
        "  elif(place_id in place_di):\n",
        "    item = place_di[place_id]\n",
        "    X_val[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "\n",
        "y_val = np.array([d['rating'] for d in val_dicts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_15MSfKKvsz"
      },
      "outputs": [],
      "source": [
        "X_test = scipy.sparse.lil_matrix((len(test_dicts), nUsers + nPlaces))\n",
        "\n",
        "for i in range(len(test_dicts)):\n",
        "  user_id = test_dicts[i]['gPlusUserId']\n",
        "  place_id = test_dicts[i]['gPlusPlaceId']\n",
        "  if(user_id in user_di and  place_id in place_di):\n",
        "    user = user_di[user_id]\n",
        "    item = place_di[place_id]\n",
        "    X_test[i,user] = 1 # One-hot encoding of user\n",
        "    X_test[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "  elif(user_id in user_di):\n",
        "    user = user_di[user_id]\n",
        "    X_test[i,user] = 1 # One-hot encoding of user\n",
        "  elif(place_id in place_di):\n",
        "    item = place_di[place_id]\n",
        "    X_test[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "\n",
        "y_test = np.array([d['rating'] for d in test_dicts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfevMX-EK0nk",
        "outputId": "2540bf58-50c3-408b-a057-3566301f86d0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>FMRegression(l2_reg_w=20, rank=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FMRegression</label><div class=\"sk-toggleable__content\"><pre>FMRegression(l2_reg_w=20, rank=0)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "FMRegression(l2_reg_w=20, rank=0)"
            ]
          },
          "execution_count": 516,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fm = als.FMRegression(init_stdev=0.1, rank=0, l2_reg_w=20)\n",
        "fm.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJLIFnuPK4Ed",
        "outputId": "aea61f72-2556-4739-f7d8-2ea1ec23e218"
      },
      "outputs": [],
      "source": [
        "y_pred_train = fm.predict(X_train)\n",
        "print(MSE(y_pred_train, y_train))\n",
        "\n",
        "y_pred_val = fm.predict(X_val)\n",
        "print(MSE(y_pred_val, y_val))\n",
        "\n",
        "y_test_pred = fm.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz55mHssdZqM"
      },
      "source": [
        "FastFM with state feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeU-22xQeMNO"
      },
      "outputs": [],
      "source": [
        "state_list = [\"AL\",\"AK\",\"AZ\",\"AR\",\"CA\",\"CO\",\"CT\",\"DE\",\"FL\",\"GA\",\"HI\",\"ID\",\"IL\",\"IN\",\"IA\",\"KS\",\"KY\",\"LA\",\"ME\",\"MD\",\"MA\",\"MI\",\"MN\",\"MS\",\"MO\",\"MT\",\"NE\",\"NV\",\"NH\",\"NJ\",\"NM\",\"NY\",\"NC\",\"ND\",\"OH\",\"OK\",\"OR\",\"PA\",\"RI\",\"SC\",\"SD\",\"TN\",\"TX\",\"UT\",\"VT\",\"VA\",\"WA\",\"WV\",\"WI\",\"WY\",\"\"]\n",
        "state_coords = [(32.806671,-86.79113),\t(61.370716,-152.404419),\t(33.729759,-111.431221),\t(34.969704,-92.373123),\t(36.116203,-119.681564),\t(39.059811,-105.311104),\t(41.597782,-72.755371),\t(39.318523,-75.507141),\t(27.766279,-81.686783),\t(33.040619,-83.643074),\t(21.094318,-157.498337),\t(44.240459,-114.478828),\t(40.349457,-88.986137),\t(39.849426,-86.258278),\t(42.011539,-93.210526),\t(38.5266,-96.726486),\t(37.66814,-84.670067),\t(31.169546,-91.867805),\t(44.693947,-69.381927),\t(39.063946,-76.802101),\t(42.230171,-71.530106),\t(43.326618,-84.536095),\t(45.694454,-93.900192),\t(32.741646,-89.678696),\t(38.456085,-92.288368),\t(46.921925,-110.454353),\t(41.12537,-98.268082),\t(38.313515,-117.055374),\t(43.452492,-71.563896),\t(40.298904,-74.521011),\t(34.840515,-106.248482),\t(42.165726,-74.948051),\t(35.630066,-79.806419),\t(47.528912,-99.784012),\t(40.388783,-82.764915),\t(35.565342,-96.928917),\t(44.572021,-122.070938),\t(40.590752,-77.209755),\t(41.680893,-71.51178),\t(33.856892,-80.945007),\t(44.299782,-99.438828),\t(35.747845,-86.692345),\t(31.054487,-97.563461),\t(40.150032,-111.862434),\t(44.045876,-72.710686),\t(37.769337,-78.169968),\t(47.400902,-121.490494),\t(38.491226,-80.954453),\t(44.268543,-89.616508),\t(42.755966,-107.30249), (0.0,0.0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QjvdYJ4dZDw"
      },
      "outputs": [],
      "source": [
        "nStates = 51\n",
        "X_train = scipy.sparse.lil_matrix((len(train_dicts), nUsers + nPlaces+nStates))\n",
        "\n",
        "for i in range(len(train_dicts)):\n",
        "    user = user_di[train_dicts[i]['gPlusUserId']]\n",
        "    item = place_di[train_dicts[i]['gPlusPlaceId']]\n",
        "    state = state_list.index(train_dicts[i]['state'])\n",
        "    X_train[i,user] = 1 # One-hot encoding of user\n",
        "    X_train[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "    X_train[i,nUsers + nPlaces + state] = 1\n",
        "\n",
        "y_train = np.array([d['rating'] for d in train_dicts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 520,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'rating': 5,\n",
              " 'reviewerName': 'william spindler',\n",
              " 'reviewText': \"This is a review that is long overdo. I've been enjoying the great pizza at this restaurant for over a year now and it's hands down the best in town. I saw a review on here saying the pizza was greasy, and I'll bet it was for a peperoni pizza. I don't know how you could put so many slices of peperoni on, where you can't even see the cheese, without a little pepperoni grease escaping. These guys at Firehouse make the pizzas that everyone else does in their commercials, you can watch as they pile the toppings a mile high on every pie. And when was the last time you saw someone slicing bell peppers and tomatoes by hand for your pizza. I honestly have a hard time understanding how these guys stay in business, but I'm glad they do. And the five dollar slice and soda lunch is probably the best value in town. Thanks guys, keep it up.\",\n",
              " 'categories': ['European Restaurant',\n",
              "  'Italian Restaurant',\n",
              "  'Pizza Restaurant'],\n",
              " 'gPlusPlaceId': '109420033090810328045',\n",
              " 'unixReviewTime': 1394826388,\n",
              " 'reviewTime': 'Mar 14, 2014',\n",
              " 'gPlusUserId': '100000032416892623125',\n",
              " 'gps': [40.178074, -122.235234],\n",
              " 'parsed_time': 0.9991038584706163,\n",
              " 'state': 'CA'}"
            ]
          },
          "execution_count": 520,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dicts[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AS868dvdkRW"
      },
      "outputs": [],
      "source": [
        "X_val = scipy.sparse.lil_matrix((len(val_dicts), nUsers + nPlaces+nStates))\n",
        "\n",
        "for i in range(len(val_dicts)):\n",
        "  user_id = val_dicts[i]['gPlusUserId']\n",
        "  place_id = val_dicts[i]['gPlusPlaceId']\n",
        "  state = state_list.index(val_dicts[i]['state'])\n",
        "  X_val[i,nUsers + nPlaces + state] = 1\n",
        "  if(user_id in user_di and  place_id in place_di):\n",
        "    user = user_di[user_id]\n",
        "    item = place_di[place_id]\n",
        "    state = state_list.index(train_dicts[i]['state'])\n",
        "    X_val[i,user] = 1 # One-hot encoding of user\n",
        "    X_val[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "  elif(user_id in user_di):\n",
        "    user = user_di[user_id]\n",
        "    X_val[i,user] = 1 # One-hot encoding of user\n",
        "  elif(place_id in place_di):\n",
        "    item = place_di[place_id]\n",
        "    X_val[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "\n",
        "y_val = np.array([d['rating'] for d in val_dicts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvcORkRJdn6E"
      },
      "outputs": [],
      "source": [
        "X_test = scipy.sparse.lil_matrix((len(test_dicts), nUsers + nPlaces+nStates))\n",
        "\n",
        "for i in range(len(test_dicts)):\n",
        "  user_id = test_dicts[i]['gPlusUserId']\n",
        "  place_id = test_dicts[i]['gPlusPlaceId']\n",
        "  state = state_list.index(test_dicts[i]['state'])\n",
        "  X_test[i,nUsers + nPlaces + state] = 1\n",
        "  if(user_id in user_di and  place_id in place_di):\n",
        "    user = user_di[user_id]\n",
        "    item = place_di[place_id]\n",
        "    X_test[i,user] = 1 # One-hot encoding of user\n",
        "    X_test[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "  elif(user_id in user_di):\n",
        "    user = user_di[user_id]\n",
        "    X_test[i,user] = 1 # One-hot encoding of user\n",
        "  elif(place_id in place_di):\n",
        "    item = place_di[place_id]\n",
        "    X_test[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "\n",
        "y_test = np.array([d['rating'] for d in test_dicts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTIzYUk6dq3a",
        "outputId": "ef732af2-5fd3-4c96-ea89-e6d371661c82"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>FMRegression(l2_reg_w=20, rank=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FMRegression</label><div class=\"sk-toggleable__content\"><pre>FMRegression(l2_reg_w=20, rank=0)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "FMRegression(l2_reg_w=20, rank=0)"
            ]
          },
          "execution_count": 523,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fm1 = als.FMRegression(init_stdev=0.1, rank=0, l2_reg_w=20)\n",
        "fm1.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwd9Gix6dtVl",
        "outputId": "c076d6a6-df8b-482d-cc74-d095108d550b"
      },
      "outputs": [],
      "source": [
        "y_pred_train = fm1.predict(X_train)\n",
        "print(MSE(y_pred_train, y_train))\n",
        "\n",
        "y_pred_val = fm1.predict(X_val)\n",
        "print(MSE(y_pred_val, y_val))\n",
        "\n",
        "y_test_pred = fm1.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na_6IWDOdWGf"
      },
      "source": [
        "FISM with just places"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_fism = scipy.sparse.lil_matrix((len(train_dicts), nPlaces*2))\n",
        "\n",
        "for i in range(len(train_dicts)):\n",
        "    user_id = train_dicts[i]['gPlusUserId']\n",
        "    item = place_di[train_dicts[i]['gPlusPlaceId']]\n",
        "    history = placesPerUser[user_id]\n",
        "    for j in history:\n",
        "      if train_dicts[i]['gPlusPlaceId'] == j: continue\n",
        "      X_train_fism[i, place_di[j]] = 1.0 / (len(history)-1)\n",
        "    X_train_fism[i,nPlaces + item] = 1\n",
        "\n",
        "y_train_fism = np.array([d['rating'] for d in train_dicts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_val_fism = scipy.sparse.lil_matrix((len(val_dicts), nPlaces*2))\n",
        "\n",
        "for i in range(len(val_dicts)):\n",
        "  user_id = val_dicts[i]['gPlusUserId']\n",
        "  item = place_di[val_dicts[i]['gPlusPlaceId']]\n",
        "  history = placesPerUser[user_id]\n",
        "  for j in history:\n",
        "    if val_dicts[i]['gPlusPlaceId'] == j: continue\n",
        "    X_val_fism[i, place_di[j]] = 1.0 / (len(history)-1)\n",
        "  X_val_fism[i,nPlaces + item] = 1\n",
        "\n",
        "y_val_fism = np.array([d['rating'] for d in val_dicts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_fism = scipy.sparse.lil_matrix((len(test_dicts), nPlaces*2))\n",
        "\n",
        "for i in range(len(test_dicts)):\n",
        "  user_id = test_dicts[i]['gPlusUserId']\n",
        "  item = place_di[test_dicts[i]['gPlusPlaceId']]\n",
        "  history = placesPerUser[user_id]\n",
        "  for j in history:\n",
        "    if test_dicts[i]['gPlusPlaceId'] == j: continue\n",
        "    X_test_fism[i, place_di[j]] = 1.0 / (len(history)-1)\n",
        "  X_test_fism[i,nPlaces + item] = 1\n",
        "\n",
        "y_test_fism = np.array([d['rating'] for d in test_dicts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVxvNRWwaN-W",
        "outputId": "b0207450-2372-4cdf-b337-ff8a6b52f235"
      },
      "outputs": [],
      "source": [
        "fm_fism = als.FMRegression(init_stdev=0.1, rank=5, l2_reg_w=20, l2_reg_V=10)\n",
        "fm_fism.fit(X_train_fism, y_train_fism)\n",
        "\n",
        "y_pred_train = fm_fism.predict(X_train_fism)\n",
        "print(MSE(y_pred_train, y_train_fism))\n",
        "\n",
        "y_pred_val = fm_fism.predict(X_val_fism)\n",
        "print(MSE(y_pred_val, y_val_fism))\n",
        "\n",
        "y_test_pred = fm_fism.predict(X_test_fism)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdUBcn2zXv74"
      },
      "source": [
        "FISm with state co-ords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W__suW_GUuP7"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train = scipy.sparse.lil_matrix((len(train_dicts), nUsers + nPlaces+2))\n",
        "\n",
        "for i in range(len(train_dicts)):\n",
        "    user = user_di[train_dicts[i]['gPlusUserId']]\n",
        "    item = place_di[train_dicts[i]['gPlusPlaceId']]\n",
        "    state = state_list.index(train_dicts[i]['state'])\n",
        "    cord = state_coords[state]\n",
        "    X_train[i,user] = 1 # One-hot encoding of user\n",
        "    X_train[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "    X_train[i,nUsers + nPlaces + 0] = cord[0]\n",
        "    X_train[i,nUsers + nPlaces + 1] = cord[1]\n",
        "\n",
        "y_train = np.array([d['rating'] for d in train_dicts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbXJEZBoX0W8"
      },
      "outputs": [],
      "source": [
        "X_val = scipy.sparse.lil_matrix((len(val_dicts), nUsers + nPlaces+2))\n",
        "\n",
        "for i in range(len(val_dicts)):\n",
        "  user_id = val_dicts[i]['gPlusUserId']\n",
        "  place_id = val_dicts[i]['gPlusPlaceId']\n",
        "  state = state_list.index(val_dicts[i]['state'])\n",
        "  cord = state_coords[state]\n",
        "  X_val[i,nUsers + nPlaces + 0] = cord[0]\n",
        "  X_val[i,nUsers + nPlaces + 1] = cord[1]\n",
        "  if(user_id in user_di and  place_id in place_di):\n",
        "    user = user_di[user_id]\n",
        "    item = place_di[place_id]\n",
        "    state = state_list.index(train_dicts[i]['state'])\n",
        "    X_val[i,user] = 1 # One-hot encoding of user\n",
        "    X_val[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "  elif(user_id in user_di):\n",
        "    user = user_di[user_id]\n",
        "    X_val[i,user] = 1 # One-hot encoding of user\n",
        "  elif(place_id in place_di):\n",
        "    item = place_di[place_id]\n",
        "    X_val[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "\n",
        "y_val = np.array([d['rating'] for d in val_dicts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ns-rwf7X3gj"
      },
      "outputs": [],
      "source": [
        "X_test = scipy.sparse.lil_matrix((len(test_dicts), nUsers + nPlaces+2))\n",
        "\n",
        "for i in range(len(test_dicts)):\n",
        "  user_id = test_dicts[i]['gPlusUserId']\n",
        "  place_id = test_dicts[i]['gPlusPlaceId']\n",
        "  state = state_list.index(test_dicts[i]['state'])\n",
        "  cord = state_coords[state]\n",
        "  X_test[i,nUsers + nPlaces + 0] = cord[0]\n",
        "  X_test[i,nUsers + nPlaces + 1] = cord[1]\n",
        "  if(user_id in user_di and  place_id in place_di):\n",
        "    user = user_di[user_id]\n",
        "    item = place_di[place_id]\n",
        "    X_test[i,user] = 1 # One-hot encoding of user\n",
        "    X_test[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "  elif(user_id in user_di):\n",
        "    user = user_di[user_id]\n",
        "    X_test[i,user] = 1 # One-hot encoding of user\n",
        "  elif(place_id in place_di):\n",
        "    item = place_di[place_id]\n",
        "    X_test[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "\n",
        "y_test = np.array([d['rating'] for d in test_dicts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOhlp3b-X6cl",
        "outputId": "f213180b-2691-412b-a27c-125a3b0885c1"
      },
      "outputs": [],
      "source": [
        "fm2 = als.FMRegression(init_stdev=0.1, rank=0, l2_reg_w=20)\n",
        "fm2.fit(X_train, y_train)\n",
        "\n",
        "y_pred_train = fm2.predict(X_train)\n",
        "print(MSE(y_pred_train, y_train))\n",
        "\n",
        "y_pred_val = fm2.predict(X_val)\n",
        "print(MSE(y_pred_val, y_val))\n",
        "\n",
        "y_test_pred = fm2.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MIiFy-ErzzU"
      },
      "source": [
        "#Fast FM with popularity of place and state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "_3LukGCksX2M"
      },
      "outputs": [],
      "source": [
        "placesPerState = defaultdict(int)\n",
        "\n",
        "for d in train_dicts:\n",
        "  placesPerState[d['state']] += 1\n",
        "\n",
        "placesPerState[\"\"] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kymMPmlr9sN"
      },
      "outputs": [],
      "source": [
        "X_train = scipy.sparse.lil_matrix((len(train_dicts), nUsers + nPlaces+2))\n",
        "\n",
        "for i in range(len(train_dicts)):\n",
        "    user = user_di[train_dicts[i]['gPlusUserId']]\n",
        "    item = place_di[train_dicts[i]['gPlusPlaceId']]\n",
        "    state = state_list.index(train_dicts[i]['state'])\n",
        "    cord = state_coords[state]\n",
        "    X_train[i,user] = 1 # One-hot encoding of user\n",
        "    X_train[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "    X_train[i,nUsers + nPlaces + 0] = len(usersPerPlace[train_dicts[i]['gPlusPlaceId']])\n",
        "    X_train[i,nUsers + nPlaces + 1] = placesPerState[train_dicts[i]['state']]\n",
        "\n",
        "y_train = np.array([d['rating'] for d in train_dicts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdeyH_01uaSb",
        "outputId": "b8185277-758a-4c56-b530-88d32e294186"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "648303"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "place_di[train_dicts[0]['gPlusPlaceId']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fL4n1gOsJhu"
      },
      "outputs": [],
      "source": [
        "X_val = scipy.sparse.lil_matrix((len(val_dicts), nUsers + nPlaces+2))\n",
        "\n",
        "for i in range(len(val_dicts)):\n",
        "  user_id = val_dicts[i]['gPlusUserId']\n",
        "  place_id = val_dicts[i]['gPlusPlaceId']\n",
        "  state = state_list.index(val_dicts[i]['state'])\n",
        "  cord = state_coords[state]\n",
        "  X_val[i,nUsers + nPlaces + 0] = len(usersPerPlace[place_id])\n",
        "  X_val[i,nUsers + nPlaces + 1] = placesPerState[val_dicts[i]['state']]\n",
        "  if(user_id in user_di and  place_id in place_di):\n",
        "    user = user_di[user_id]\n",
        "    item = place_di[place_id]\n",
        "    state = state_list.index(train_dicts[i]['state'])\n",
        "    X_val[i,user] = 1 # One-hot encoding of user\n",
        "    X_val[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "  elif(user_id in user_di):\n",
        "    user = user_di[user_id]\n",
        "    X_val[i,user] = 1 # One-hot encoding of user\n",
        "  elif(place_id in place_di):\n",
        "    item = place_di[place_id]\n",
        "    X_val[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "\n",
        "y_val = np.array([d['rating'] for d in val_dicts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2TnYsKgsGvu"
      },
      "outputs": [],
      "source": [
        "X_test = scipy.sparse.lil_matrix((len(test_dicts), nUsers + nPlaces+2))\n",
        "\n",
        "for i in range(len(test_dicts)):\n",
        "  user_id = test_dicts[i]['gPlusUserId']\n",
        "  place_id = test_dicts[i]['gPlusPlaceId']\n",
        "  state = state_list.index(test_dicts[i]['state'])\n",
        "  cord = state_coords[state]\n",
        "  X_test[i,nUsers + nPlaces + 0] = len(usersPerPlace[place_id])\n",
        "  X_test[i,nUsers + nPlaces + 1] = placesPerState[test_dicts[i]['state']]\n",
        "  if(user_id in user_di and  place_id in place_di):\n",
        "    user = user_di[user_id]\n",
        "    item = place_di[place_id]\n",
        "    X_test[i,user] = 1 # One-hot encoding of user\n",
        "    X_test[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "  elif(user_id in user_di):\n",
        "    user = user_di[user_id]\n",
        "    X_test[i,user] = 1 # One-hot encoding of user\n",
        "  elif(place_id in place_di):\n",
        "    item = place_di[place_id]\n",
        "    X_test[i,nUsers + item] = 1 # One-hot encoding of item\n",
        "\n",
        "y_test = np.array([d['rating'] for d in test_dicts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crBTRCcqsLSt",
        "outputId": "888db574-2b16-452f-8592-9d4b255d9c61"
      },
      "outputs": [],
      "source": [
        "fm3 = als.FMRegression(init_stdev=0.1, rank=0, l2_reg_w=5)\n",
        "fm3.fit(X_train, y_train)\n",
        "\n",
        "y_pred_train = fm3.predict(X_train)\n",
        "print(MSE(y_pred_train, y_train))\n",
        "\n",
        "y_pred_val = fm3.predict(X_val)\n",
        "print(MSE(y_pred_val, y_val))\n",
        "\n",
        "y_test_pred = fm3.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYAooao8xA3N",
        "outputId": "1a4bd72c-ac11-42ce-fac9-be744e9b9164"
      },
      "outputs": [],
      "source": [
        "print(MSE(y_test_pred, y_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
